{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOne02rRbb4BA/eyOwwGRD6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjha1/Deep-Learning/blob/main/12_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **PyTorch -**\n",
        "\n",
        "#### **Introduction**\n",
        "\n",
        "* PyTorch is an **open-source machine learning framework**.\n",
        "* Mainly used for **developing and training deep learning models**.\n",
        "* Developed by **Facebook's AI Research Lab** and released in **2016**.\n",
        "* Offers a **flexible and dynamic approach** to building neural networks.\n",
        "* Popular among researchers and developers.\n",
        "\n",
        "#### **Key Features**\n",
        "\n",
        "1. **Dynamic Computational Graphs**\n",
        "\n",
        "   * Graphs are **built and modified on-the-fly** as the program runs.\n",
        "   * Allows for **intuitive and flexible** model development.\n",
        "   * Supports standard **Python control flow** and easy debugging.\n",
        "\n",
        "2. **Automatic Differentiation**\n",
        "\n",
        "   * Efficient computation of **gradients for backpropagation**.\n",
        "   * Supports **data loading**, **model building**, **optimization**, and **evaluation**.\n",
        "\n",
        "3. **GPU Acceleration**\n",
        "\n",
        "   * Enables training on **GPUs** to **speed up computations**.\n",
        "   * Backed by a **large and active community** with many tutorials and pre-trained models.\n",
        "\n",
        "4. **Comparison with TensorFlow**\n",
        "\n",
        "   * TensorFlow: uses **static computation graphs**.\n",
        "   * PyTorch: uses **dynamic graphs** for more **flexibility and ease of use**.\n",
        "\n",
        "#### **Use in Industry and Research**\n",
        "\n",
        "* **Widely used in research**.\n",
        "* Gaining popularity in **industry applications**.\n",
        "* Provides a **user-friendly platform** for building deep learning models.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jnXuEeofUdZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¥ **PyTorch - In-Depth**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. PyTorch Architecture Overview**\n",
        "\n",
        "* **Core Components**:\n",
        "\n",
        "  1. **Tensors** â€“ Multidimensional arrays, like NumPy arrays but with GPU support.\n",
        "  2. **Autograd** â€“ Automatic differentiation engine for backpropagation.\n",
        "  3. **nn.Module** â€“ Base class for all neural networks.\n",
        "  4. **torch.optim** â€“ Optimization algorithms (SGD, Adam, etc.).\n",
        "  5. **Data utilities** â€“ `torch.utils.data.Dataset` & `DataLoader` for handling data.\n",
        "\n",
        "* **Workflow**:\n",
        "\n",
        "  * Define model using `nn.Module`\n",
        "  * Forward pass â†’ loss calculation\n",
        "  * Backward pass using `autograd`\n",
        "  * Optimizer updates parameters\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Tensors in PyTorch**\n",
        "\n",
        "* Similar to **NumPy arrays**, but can run on **GPU** using `.to(\"cuda\")` or `.cuda()`.\n",
        "\n",
        "* Created using:\n",
        "\n",
        "  ```python\n",
        "  x = torch.tensor([1.0, 2.0])\n",
        "  y = torch.zeros(2, 3)\n",
        "  z = torch.rand(4, 4)\n",
        "  ```\n",
        "\n",
        "* **Operations**: element-wise, matrix multiplication, reshaping (`.view()` or `.reshape()`), etc.\n",
        "\n",
        "* **Device control**:\n",
        "\n",
        "  ```python\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  x = x.to(device)\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Autograd - Automatic Differentiation**\n",
        "\n",
        "* **`requires_grad=True`** tracks computation for automatic differentiation.\n",
        "\n",
        "* Builds **Dynamic Computation Graph** at runtime.\n",
        "\n",
        "* Example:\n",
        "\n",
        "  ```python\n",
        "  x = torch.tensor([2.0], requires_grad=True)\n",
        "  y = x**2\n",
        "  y.backward()\n",
        "  print(x.grad)  # Output: tensor([4.])\n",
        "  ```\n",
        "\n",
        "* **`.backward()`** computes gradients.\n",
        "\n",
        "* Use **`with torch.no_grad():`** to disable gradient tracking during inference.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. `nn.Module` and Model Building**\n",
        "\n",
        "* Every model in PyTorch is a subclass of `nn.Module`.\n",
        "\n",
        "#### **Example:**\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.linear = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "```\n",
        "\n",
        "* Key methods:\n",
        "\n",
        "  * `__init__()`: define layers\n",
        "  * `forward()`: define forward pass\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Optimizers (torch.optim)**\n",
        "\n",
        "* PyTorch provides various optimizers:\n",
        "\n",
        "  * `SGD`, `Adam`, `RMSprop`, etc.\n",
        "\n",
        "* Example:\n",
        "\n",
        "  ```python\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "  ```\n",
        "\n",
        "* Steps:\n",
        "\n",
        "  1. `optimizer.zero_grad()`\n",
        "  2. `loss.backward()`\n",
        "  3. `optimizer.step()`\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Data Loading Utilities**\n",
        "\n",
        "* **`Dataset`**: Custom data logic\n",
        "* **`DataLoader`**: Batches, shuffling, multiprocessing\n",
        "* Example:\n",
        "\n",
        "  ```python\n",
        "  from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "  class MyDataset(Dataset):\n",
        "      def __init__(self):\n",
        "          self.data = torch.randn(100, 10)\n",
        "\n",
        "      def __len__(self):\n",
        "          return len(self.data)\n",
        "\n",
        "      def __getitem__(self, idx):\n",
        "          return self.data[idx]\n",
        "\n",
        "  loader = DataLoader(MyDataset(), batch_size=32, shuffle=True)\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **7. Training Loop Structure**\n",
        "\n",
        "```python\n",
        "for epoch in range(epochs):\n",
        "    for inputs, targets in dataloader:\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… **Tips for Beginners**\n",
        "\n",
        "* Use `.to(device)` to move model and tensors to GPU.\n",
        "* Track gradients only when training (not during inference).\n",
        "* Use **TensorBoard**, **WandB**, or **Matplotlib** to monitor training.\n",
        "* Save models with `torch.save()` and load using `torch.load()`.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-PxPvKEaUtQ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L0WSzu4gS6MC"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors\n",
        "At its core. PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number."
      ],
      "metadata": {
        "id": "xQz3cSoBWBMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1=torch.tensor(6.0)\n",
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOBwRXA0Vvfj",
        "outputId": "8bb0413e-6a50-4ecd-8d24-5e0aef6e571b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdLU6xBxWcod",
        "outputId": "5b273e06-49b3-41ac-8ffb-8f05ede5b4b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vector**"
      ],
      "metadata": {
        "id": "2Eg8N49SXeL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2=torch.tensor([1.,2,3,4])\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVshWPm-WxTP",
        "outputId": "0be447e1-4aea-4bef-d12c-129bcdb435b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix**"
      ],
      "metadata": {
        "id": "EDjocnojXVwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t3=torch.tensor([[5,6,7],\n",
        "                [8,9,2],\n",
        "                [1,2,3]])\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8N6QZFoW2RV",
        "outputId": "51f1126f-ff04-4b4c-a39e-1b865e26a3fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5, 6, 7],\n",
              "        [8, 9, 2],\n",
              "        [1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKRc_x-SXMeS",
        "outputId": "2c0a0846-2ce2-471c-dc72-53c82d0d7a7b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3-Dimensional-Array**"
      ],
      "metadata": {
        "id": "5zU1xWVbXj1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t4 = torch.tensor([[[1,2,3],[4,5,6],[8,9,10]],[[9,8,7],[6,5,4],[3,2,1]]])\n",
        "t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5ekGhyZXO7F",
        "outputId": "67bbc0c0-faf6-45c3-aaae-fa9f874c5723"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2,  3],\n",
              "         [ 4,  5,  6],\n",
              "         [ 8,  9, 10]],\n",
              "\n",
              "        [[ 9,  8,  7],\n",
              "         [ 6,  5,  4],\n",
              "         [ 3,  2,  1]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t4.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2z65ETjYCqL",
        "outputId": "d68d67e8-b475-4db5-f9a7-b4705eb08928"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NOISlUwZB_j",
        "outputId": "70fe5b1e-bb8c-4374-ac64-32c2fc1182e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeLadnwjZcS8",
        "outputId": "ed0bf891-5531-4fe2-b3f5-a14e51c62090"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HgI4JhtZfmc",
        "outputId": "d01ab43c-03b0-4a95-db79-0a102f0611b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhqMSGCQZxJQ",
        "outputId": "508ac846-5c66-4dd4-a8b3-42ab3e84ee0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSRI5GvrZz7r",
        "outputId": "54054036-f0b6-4e05-a9f8-b89c2d8bdaff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JTSU6__ZlDe",
        "outputId": "c3e496f4-4453-4bb6-a4aa-a5ee5fac16cd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t4.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ykXJaGsZnjp",
        "outputId": "7b421adf-bf5f-445e-e466-15f983150d64"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ðŸ§® **Tensor Operations and Gradients in PyTorch**\n",
        "\n",
        "### **1. Creating Tensors**\n"
      ],
      "metadata": {
        "id": "e-0hUCRxu8JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)"
      ],
      "metadata": {
        "id": "q2yvFYXVZ4X7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `x`, `w`, and `b` are all scalar tensors (single float values).\n",
        "* `w` and `b` have `requires_grad=True`, which tells PyTorch to **track gradients** for them (useful for autograd).\n",
        "\n",
        "\n",
        "\n",
        "### **2. Arithmetic Operation**"
      ],
      "metadata": {
        "id": "EmhJh-QMvBOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = w * x + b\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYiQs8FGuxTb",
        "outputId": "b5acd162-c27f-4f36-a29c-423c462aa5c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Combines tensors using standard arithmetic.\n",
        "\n",
        "* Value of `y`:\n",
        "  $y = w \\times x + b = 4 \\times 3 + 5 = 17$\n",
        "\n",
        "* PyTorch automatically tracks this computation for backpropagation.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Gradient Computation using Autograd**"
      ],
      "metadata": {
        "id": "DM_M3guKvGtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "i74hXlPAux5-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Computes the **derivatives of `y` w\\.r.t. tensors with `requires_grad=True`**, i.e., `w` and `b`.\n",
        "\n",
        "* This uses PyTorch's **autograd** system (automatic differentiation engine).\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… **Key Concept: Autograd**\n",
        "\n",
        "* PyTorch keeps track of operations using a **dynamic computation graph**.\n",
        "* `.backward()` triggers the computation of gradients.\n",
        "* After `.backward()`, you can access gradients via:"
      ],
      "metadata": {
        "id": "B7SvjeN9vYMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§  **Viewing Gradients in PyTorch**\n",
        "\n",
        "### **1. Accessing Gradients**\n",
        "\n",
        "* PyTorch stores computed gradients in the `.grad` attribute of tensors:"
      ],
      "metadata": {
        "id": "8V3fBTsvw5Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('dy/dx:', x.grad)  # None\n",
        "print('dy/dw:', w.grad)  # tensor(3.)\n",
        "print('dy/db:', b.grad)  # tensor(1.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnivpC5Fw8kf",
        "outputId": "8d648973-98b0-4623-da6a-d033e153b85b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **2. Explanation of Gradient Values**\n",
        "\n",
        "| Derivative | Value  | Reason                                                     |\n",
        "| ---------- | ------ | ---------------------------------------------------------- |\n",
        "| dy/dx      | `None` | `x` does **not** have `requires_grad=True`, so no gradient |\n",
        "| dy/dw      | `3.`   | Gradient of `y = wx + b` w\\.r.t. `w` is `x = 3`            |\n",
        "| dy/db      | `1.`   | Gradient of `y = wx + b` w\\.r.t. `b` is `1` (âˆ‚y/âˆ‚b = 1)    |\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… **Key Notes:**\n",
        "\n",
        "* `.grad` gives **partial derivatives** of output w\\.r.t. each tensor with `requires_grad=True`.\n",
        "* `x.grad` is `None` because we didnâ€™t set `requires_grad=True` for `x`.\n",
        "* The term **\"grad\"** is short for **gradient**, which means derivative (commonly used in ML).\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IQpgik0DwmSK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sulLD9MOxPZf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§® PyTorch Tensor Functions\n",
        "\n",
        "### ðŸ”¹ 1. Creating a Tensor with a Fixed Value\n",
        "\n",
        "----\n",
        "\n",
        "ðŸ“Œ This creates a **3Ã—2 tensor** where **every element is 42**."
      ],
      "metadata": {
        "id": "Ln92NWGAzqd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t6 = torch.full((3, 2), 42)\n",
        "t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5KbUn4p0HvS",
        "outputId": "03b7e580-792d-4e38-8a53-27a9fa91130d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ”¹ 2. Tensor Concatenation"
      ],
      "metadata": {
        "id": "IEEMoAMP0YLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_new=torch.tensor([[5,6],\n",
        "                [8,2],\n",
        "                [1,2]])\n",
        "t_new,t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii-hInPh1OUH",
        "outputId": "0ea8c55d-b08c-4a44-c1aa-8b52d58fe1a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5, 6],\n",
              "         [8, 2],\n",
              "         [1, 2]]),\n",
              " tensor([[42, 42],\n",
              "         [42, 42],\n",
              "         [42, 42]]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t7 = torch.cat((t_new, t6))\n",
        "t7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lQZHVuP0qQ3",
        "outputId": "d0f11a66-ee74-4cc1-8b95-6443f0f569bd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5,  6],\n",
              "        [ 8,  2],\n",
              "        [ 1,  2],\n",
              "        [42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ðŸ“Œ `torch.cat()` joins tensors **along the first dimension (rows)** if not specified otherwise.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary:\n",
        "\n",
        "| Function                 | Description                                           |\n",
        "| ------------------------ | ----------------------------------------------------- |\n",
        "| `torch.full(shape, val)` | Creates a tensor filled with the given constant `val` |\n",
        "| `torch.cat(tensors)`     | Concatenates tensors with compatible shapes           |\n",
        "\n",
        "ðŸ§  Make sure the tensors have **matching dimensions except along the axis you're concatenating** (default is `dim=0`).\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yxBYXCE30Edt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t8=torch.sin(t7)\n",
        "t8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8mqKjeUzn5n",
        "outputId": "26cade54-d2f8-454e-eaa0-de5f586920f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794],\n",
              "        [ 0.9894,  0.9093],\n",
              "        [ 0.8415,  0.9093],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t9=torch.reshape(t8,(3,2,2))\n",
        "t9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC6iEly258CO",
        "outputId": "7eee7846-449d-46b0-b352-6c8375b8d671"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9589, -0.2794],\n",
              "         [ 0.9894,  0.9093]],\n",
              "\n",
              "        [[ 0.8415,  0.9093],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can learn more about tensor operations here: [https://pytorch.org/docs/stable/torch.html](https://pytorch.org/docs/stable/torch.html). Experiment with some more tensor functions and operations using the empty cells below."
      ],
      "metadata": {
        "id": "zFPgbGrj6nv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ðŸ”„ Interoperability with NumPy (PyTorch + NumPy)\n",
        "\n",
        "### ðŸ”¹ NumPy kya hai?\n",
        "\n",
        "**NumPy** is a powerful library for numerical computing in Python.\n",
        "\n",
        "**Used with:**\n",
        "\n",
        "* **Pandas** â€“ Data analysis\n",
        "* **Matplotlib** â€“ Visualization\n",
        "* **OpenCV** â€“ Image processing\n",
        "\n",
        "**Why use with PyTorch?**\n",
        "\n",
        "> PyTorch doesn't reinvent the wheel â€” it works well with NumPy arrays to benefit from Pythonâ€™s existing data science ecosystem.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¸ NumPy Array Creation Example"
      ],
      "metadata": {
        "id": "5bRp9NWk761T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1, 2], [3, 4.1]])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHv_5Wz-7-HL",
        "outputId": "3d41dd6b-533e-42cf-85ea-b866d556f9a6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1. , 2. ],\n",
              "       [3. , 4.1]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ðŸ”¸ Converting NumPy array to PyTorch Tensor"
      ],
      "metadata": {
        "id": "tA2lRfio8Ol7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.from_numpy(x)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBZDhCF_8Dvy",
        "outputId": "3ab49491-4832-4995-e4bf-52bcf05d081d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 2.0000],\n",
              "        [3.0000, 4.1000]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> âœ… `torch.from_numpy()` **shares memory** with NumPy â€” meaning changes in one reflect in the other unless explicitly copied.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary Table\n",
        "\n",
        "| Operation       | PyTorch Code                 | Notes                   |\n",
        "| --------------- | ---------------------------- | ----------------------- |\n",
        "| NumPy â†’ PyTorch | `torch.from_numpy(np_array)` | Shares memory (no copy) |\n",
        "| PyTorch â†’ NumPy | `tensor.numpy()`             | Must be CPU tensor      |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-0u7gtFz8Iy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype,y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15HL2v7H8S1O",
        "outputId": "7ab79b24-1a44-4087-9911-7615201c1128"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can convert a PyTorch tensor to a Numpy array using the .numpy method of a tensor"
      ],
      "metadata": {
        "id": "gEjH_hDRhGJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMaAGyu1hgXy",
        "outputId": "18a9ca76-f954-400a-ba34-6f3ca8924b75"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 2.0000],\n",
              "        [3.0000, 4.1000]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=y.numpy()\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc8b-9H7hOQE",
        "outputId": "f58389b3-818f-489f-fab9-57765b007a04"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1. , 2. ],\n",
              "       [3. , 4.1]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBhNaP-MhJ2E",
        "outputId": "57b375ab-6789-4853-9d4a-dde5052728d4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**The interoperability between PyTorch and Numpy is essential** because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
        "\n",
        "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
        "\n",
        "1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
        "2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "OC55nIQgh3LC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Making Training Data"
      ],
      "metadata": {
        "id": "gYtrXpN6ihmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([\n",
        "    [73, 67, 43],\n",
        "    [91, 88, 64],\n",
        "    [87, 134, 58],\n",
        "    [102, 43, 37],\n",
        "    [69, 96, 70]\n",
        "], dtype='float32')\n"
      ],
      "metadata": {
        "id": "RM8wRFr4h5ff"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets (apples, oranges)\n",
        "target = np.array([\n",
        "    [56, 70],\n",
        "    [81, 101],\n",
        "    [119, 133],\n",
        "    [22, 37],\n",
        "    [103, 119]\n",
        "], dtype='float32')\n"
      ],
      "metadata": {
        "id": "PHLTpIYTipM9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¹ Convert Input and Target to Tensors"
      ],
      "metadata": {
        "id": "0plXnbgfiuzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "target = torch.from_numpy(target)\n",
        "\n",
        "print(inputs, \"\\n\")\n",
        "print(target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1h43Eyhityb",
        "outputId": "63088205-295a-47e6-88a6-7a90db7f9b81"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]]) \n",
            "\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w=torch.randn(2,3,requires_grad=True)\n",
        "b=torch.randn(2,requires_grad=True)\n",
        "w,b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4FCfkIVi1oV",
        "outputId": "13a83d76-8016-4420-edfb-9569e4fbf64e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.5965,  0.8186,  0.7135],\n",
              "         [-1.5023,  1.5681,  0.3915]], requires_grad=True),\n",
              " tensor([ 1.4868, -1.7268], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M=w.T"
      ],
      "metadata": {
        "id": "xnZLVsqMj5mH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape,w.T.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCnknaL4kmrF",
        "outputId": "08742fc1-03b2-49ee-cd10-cd0ce1202962"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 3]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model1(y):\n",
        "    return torch.matmul(y, w.T) + b\n"
      ],
      "metadata": {
        "id": "gXAo8i3Mll6K"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "  return x @ w.T + b"
      ],
      "metadata": {
        "id": "0OMxctkBjRp9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds=model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB6vfcZwj3p7",
        "outputId": "96fe04ea-8495-484c-8603-4d7e35fc8800"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[130.5627,  10.4983],\n",
              "        [173.4749,  24.6075],\n",
              "        [204.4653, 100.3995],\n",
              "        [123.9342, -73.0525],\n",
              "        [171.1810,  72.5526]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=model1(inputs)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViKvODp7l3e1",
        "outputId": "d2092cc1-e586-4ac7-bc40-5d327d3a083a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[130.5627,  10.4983],\n",
              "        [173.4749,  24.6075],\n",
              "        [204.4653, 100.3995],\n",
              "        [123.9342, -73.0525],\n",
              "        [171.1810,  72.5526]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE(actual,target):\n",
        "  diff=actual-target\n",
        "  return torch.sum(diff*diff)/diff.numel()\n"
      ],
      "metadata": {
        "id": "nCDO4KS6mb6E"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss=MSE(preds,target)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqSNP2CIy43t",
        "outputId": "c3c33a6e-1b56-453a-ad7c-fef86c084658"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6116.2705, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "O80liFsQy9Ru"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w,\"\\n\")\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbRpqKBozD7v",
        "outputId": "afd64a84-27a8-45d9-f8a5-a2f0a5fa30f6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5965,  0.8186,  0.7135],\n",
            "        [-1.5023,  1.5681,  0.3915]], requires_grad=True) \n",
            "\n",
            "tensor([[ 7279.1094,  7102.8770,  4525.1616],\n",
            "        [-5712.3613, -4853.7646, -3332.3557]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad,\"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FotKlmhbzQhk",
        "outputId": "1d52e436-c02e-4b52-c4c6-b6cb2825bfe4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]]) \n",
            "\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQEipA8rzc5K",
        "outputId": "6ba10e98-644b-4823-f314-68421fec72d5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[130.5627,  10.4983],\n",
              "        [173.4749,  24.6075],\n",
              "        [204.4653, 100.3995],\n",
              "        [123.9342, -73.0525],\n",
              "        [171.1810,  72.5526]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=MSE(preds,target)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngYQv51_zmWb",
        "outputId": "c9ce18e4-23f4-4e68-a748-083e84031d2e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6116.2705, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "nJSnO8vGzyoO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w.grad,\"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5Ygt8w2z9kf",
        "outputId": "76a46d90-7c30-4d6e-dcf4-395e5919b632"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 7279.1094,  7102.8770,  4525.1616],\n",
            "        [-5712.3613, -4853.7646, -3332.3557]]) \n",
            "\n",
            "tensor([ 84.5236, -64.9989])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  w-=w.grad*1e-5\n",
        "  b-=b.grad*1e-5\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()"
      ],
      "metadata": {
        "id": "N0qmnk6L0DiA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w,\"\\n\")\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Izy64g30LYK",
        "outputId": "44429b64-c3b4-48d4-b913-f9052a4950db"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5238,  0.7476,  0.6682],\n",
            "        [-1.4452,  1.6166,  0.4248]], requires_grad=True) \n",
            "\n",
            "tensor([ 1.4859, -1.7261], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NG_2QX20Pnf",
        "outputId": "81a39f8c-ad84-4658-a9d2-a7ceba3c6d9d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[118.5434,  19.3540],\n",
              "        [157.7034,  36.2104],\n",
              "        [185.9892, 113.8067],\n",
              "        [111.7801, -63.9052],\n",
              "        [156.1711,  83.4871]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=MSE(preds,target)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqmmWjLj0gTq",
        "outputId": "51c8bba4-e5c6-48fa-fb53-2a6352f005ee"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4374.4385, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(400):\n",
        "  preds=model(inputs)\n",
        "  loss=MSE(preds,target)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w-=w.grad*1e-5\n",
        "    b-=b.grad*1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "  print(f\"(Epoch: {i}/{100}) &  Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejH-SYdg0n45",
        "outputId": "5f57aad6-c77c-4b6b-9f6a-a901394d6d5a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch: 0/100) &  Loss: 4374.4384765625\n",
            "(Epoch: 1/100) &  Loss: 3197.49853515625\n",
            "(Epoch: 2/100) &  Loss: 2401.27001953125\n",
            "(Epoch: 3/100) &  Loss: 1861.6370849609375\n",
            "(Epoch: 4/100) &  Loss: 1494.958251953125\n",
            "(Epoch: 5/100) &  Loss: 1244.870361328125\n",
            "(Epoch: 6/100) &  Loss: 1073.387451171875\n",
            "(Epoch: 7/100) &  Loss: 954.9134521484375\n",
            "(Epoch: 8/100) &  Loss: 872.1976318359375\n",
            "(Epoch: 9/100) &  Loss: 813.6151123046875\n",
            "(Epoch: 10/100) &  Loss: 771.3317260742188\n",
            "(Epoch: 11/100) &  Loss: 740.06689453125\n",
            "(Epoch: 12/100) &  Loss: 716.2627563476562\n",
            "(Epoch: 13/100) &  Loss: 697.5203857421875\n",
            "(Epoch: 14/100) &  Loss: 682.2232666015625\n",
            "(Epoch: 15/100) &  Loss: 669.2815551757812\n",
            "(Epoch: 16/100) &  Loss: 657.9599609375\n",
            "(Epoch: 17/100) &  Loss: 647.7632446289062\n",
            "(Epoch: 18/100) &  Loss: 638.3564453125\n",
            "(Epoch: 19/100) &  Loss: 629.5144653320312\n",
            "(Epoch: 20/100) &  Loss: 621.084228515625\n",
            "(Epoch: 21/100) &  Loss: 612.9625854492188\n",
            "(Epoch: 22/100) &  Loss: 605.0801391601562\n",
            "(Epoch: 23/100) &  Loss: 597.3887329101562\n",
            "(Epoch: 24/100) &  Loss: 589.8558349609375\n",
            "(Epoch: 25/100) &  Loss: 582.4598388671875\n",
            "(Epoch: 26/100) &  Loss: 575.1852416992188\n",
            "(Epoch: 27/100) &  Loss: 568.0211791992188\n",
            "(Epoch: 28/100) &  Loss: 560.9599609375\n",
            "(Epoch: 29/100) &  Loss: 553.996337890625\n",
            "(Epoch: 30/100) &  Loss: 547.126220703125\n",
            "(Epoch: 31/100) &  Loss: 540.3465576171875\n",
            "(Epoch: 32/100) &  Loss: 533.6549072265625\n",
            "(Epoch: 33/100) &  Loss: 527.04931640625\n",
            "(Epoch: 34/100) &  Loss: 520.5279541015625\n",
            "(Epoch: 35/100) &  Loss: 514.0897216796875\n",
            "(Epoch: 36/100) &  Loss: 507.73272705078125\n",
            "(Epoch: 37/100) &  Loss: 501.45654296875\n",
            "(Epoch: 38/100) &  Loss: 495.25958251953125\n",
            "(Epoch: 39/100) &  Loss: 489.14044189453125\n",
            "(Epoch: 40/100) &  Loss: 483.09881591796875\n",
            "(Epoch: 41/100) &  Loss: 477.13299560546875\n",
            "(Epoch: 42/100) &  Loss: 471.24273681640625\n",
            "(Epoch: 43/100) &  Loss: 465.4261169433594\n",
            "(Epoch: 44/100) &  Loss: 459.6830139160156\n",
            "(Epoch: 45/100) &  Loss: 454.0121154785156\n",
            "(Epoch: 46/100) &  Loss: 448.41278076171875\n",
            "(Epoch: 47/100) &  Loss: 442.8837890625\n",
            "(Epoch: 48/100) &  Loss: 437.4244079589844\n",
            "(Epoch: 49/100) &  Loss: 432.03387451171875\n",
            "(Epoch: 50/100) &  Loss: 426.7108459472656\n",
            "(Epoch: 51/100) &  Loss: 421.45501708984375\n",
            "(Epoch: 52/100) &  Loss: 416.2655334472656\n",
            "(Epoch: 53/100) &  Loss: 411.14093017578125\n",
            "(Epoch: 54/100) &  Loss: 406.0809631347656\n",
            "(Epoch: 55/100) &  Loss: 401.0845947265625\n",
            "(Epoch: 56/100) &  Loss: 396.1513366699219\n",
            "(Epoch: 57/100) &  Loss: 391.27996826171875\n",
            "(Epoch: 58/100) &  Loss: 386.47003173828125\n",
            "(Epoch: 59/100) &  Loss: 381.7203369140625\n",
            "(Epoch: 60/100) &  Loss: 377.03057861328125\n",
            "(Epoch: 61/100) &  Loss: 372.39959716796875\n",
            "(Epoch: 62/100) &  Loss: 367.8269958496094\n",
            "(Epoch: 63/100) &  Loss: 363.3119812011719\n",
            "(Epoch: 64/100) &  Loss: 358.853759765625\n",
            "(Epoch: 65/100) &  Loss: 354.45147705078125\n",
            "(Epoch: 66/100) &  Loss: 350.104736328125\n",
            "(Epoch: 67/100) &  Loss: 345.8124084472656\n",
            "(Epoch: 68/100) &  Loss: 341.57415771484375\n",
            "(Epoch: 69/100) &  Loss: 337.38916015625\n",
            "(Epoch: 70/100) &  Loss: 333.2568359375\n",
            "(Epoch: 71/100) &  Loss: 329.176513671875\n",
            "(Epoch: 72/100) &  Loss: 325.1474914550781\n",
            "(Epoch: 73/100) &  Loss: 321.1690979003906\n",
            "(Epoch: 74/100) &  Loss: 317.2405700683594\n",
            "(Epoch: 75/100) &  Loss: 313.3616638183594\n",
            "(Epoch: 76/100) &  Loss: 309.5313415527344\n",
            "(Epoch: 77/100) &  Loss: 305.749267578125\n",
            "(Epoch: 78/100) &  Loss: 302.0146789550781\n",
            "(Epoch: 79/100) &  Loss: 298.32696533203125\n",
            "(Epoch: 80/100) &  Loss: 294.68572998046875\n",
            "(Epoch: 81/100) &  Loss: 291.09014892578125\n",
            "(Epoch: 82/100) &  Loss: 287.5398864746094\n",
            "(Epoch: 83/100) &  Loss: 284.0340270996094\n",
            "(Epoch: 84/100) &  Loss: 280.5723571777344\n",
            "(Epoch: 85/100) &  Loss: 277.1541442871094\n",
            "(Epoch: 86/100) &  Loss: 273.77886962890625\n",
            "(Epoch: 87/100) &  Loss: 270.446044921875\n",
            "(Epoch: 88/100) &  Loss: 267.15484619140625\n",
            "(Epoch: 89/100) &  Loss: 263.90509033203125\n",
            "(Epoch: 90/100) &  Loss: 260.69635009765625\n",
            "(Epoch: 91/100) &  Loss: 257.52783203125\n",
            "(Epoch: 92/100) &  Loss: 254.3991241455078\n",
            "(Epoch: 93/100) &  Loss: 251.3096160888672\n",
            "(Epoch: 94/100) &  Loss: 248.2589569091797\n",
            "(Epoch: 95/100) &  Loss: 245.24649047851562\n",
            "(Epoch: 96/100) &  Loss: 242.2720184326172\n",
            "(Epoch: 97/100) &  Loss: 239.334716796875\n",
            "(Epoch: 98/100) &  Loss: 236.43441772460938\n",
            "(Epoch: 99/100) &  Loss: 233.5706024169922\n",
            "(Epoch: 100/100) &  Loss: 230.7424774169922\n",
            "(Epoch: 101/100) &  Loss: 227.9500732421875\n",
            "(Epoch: 102/100) &  Loss: 225.19265747070312\n",
            "(Epoch: 103/100) &  Loss: 222.4698944091797\n",
            "(Epoch: 104/100) &  Loss: 219.78115844726562\n",
            "(Epoch: 105/100) &  Loss: 217.12631225585938\n",
            "(Epoch: 106/100) &  Loss: 214.50479125976562\n",
            "(Epoch: 107/100) &  Loss: 211.91592407226562\n",
            "(Epoch: 108/100) &  Loss: 209.3598175048828\n",
            "(Epoch: 109/100) &  Loss: 206.8356475830078\n",
            "(Epoch: 110/100) &  Loss: 204.3430938720703\n",
            "(Epoch: 111/100) &  Loss: 201.88180541992188\n",
            "(Epoch: 112/100) &  Loss: 199.4515380859375\n",
            "(Epoch: 113/100) &  Loss: 197.0515594482422\n",
            "(Epoch: 114/100) &  Loss: 194.68185424804688\n",
            "(Epoch: 115/100) &  Loss: 192.3416748046875\n",
            "(Epoch: 116/100) &  Loss: 190.031005859375\n",
            "(Epoch: 117/100) &  Loss: 187.74932861328125\n",
            "(Epoch: 118/100) &  Loss: 185.49610900878906\n",
            "(Epoch: 119/100) &  Loss: 183.27120971679688\n",
            "(Epoch: 120/100) &  Loss: 181.0741424560547\n",
            "(Epoch: 121/100) &  Loss: 178.9046630859375\n",
            "(Epoch: 122/100) &  Loss: 176.76242065429688\n",
            "(Epoch: 123/100) &  Loss: 174.64700317382812\n",
            "(Epoch: 124/100) &  Loss: 172.55801391601562\n",
            "(Epoch: 125/100) &  Loss: 170.4952850341797\n",
            "(Epoch: 126/100) &  Loss: 168.45843505859375\n",
            "(Epoch: 127/100) &  Loss: 166.44696044921875\n",
            "(Epoch: 128/100) &  Loss: 164.46080017089844\n",
            "(Epoch: 129/100) &  Loss: 162.4993896484375\n",
            "(Epoch: 130/100) &  Loss: 160.56268310546875\n",
            "(Epoch: 131/100) &  Loss: 158.65017700195312\n",
            "(Epoch: 132/100) &  Loss: 156.76161193847656\n",
            "(Epoch: 133/100) &  Loss: 154.896728515625\n",
            "(Epoch: 134/100) &  Loss: 153.05514526367188\n",
            "(Epoch: 135/100) &  Loss: 151.23660278320312\n",
            "(Epoch: 136/100) &  Loss: 149.44082641601562\n",
            "(Epoch: 137/100) &  Loss: 147.66754150390625\n",
            "(Epoch: 138/100) &  Loss: 145.9165496826172\n",
            "(Epoch: 139/100) &  Loss: 144.18740844726562\n",
            "(Epoch: 140/100) &  Loss: 142.47982788085938\n",
            "(Epoch: 141/100) &  Loss: 140.79360961914062\n",
            "(Epoch: 142/100) &  Loss: 139.1285400390625\n",
            "(Epoch: 143/100) &  Loss: 137.48431396484375\n",
            "(Epoch: 144/100) &  Loss: 135.86062622070312\n",
            "(Epoch: 145/100) &  Loss: 134.25717163085938\n",
            "(Epoch: 146/100) &  Loss: 132.6739044189453\n",
            "(Epoch: 147/100) &  Loss: 131.1103973388672\n",
            "(Epoch: 148/100) &  Loss: 129.5663604736328\n",
            "(Epoch: 149/100) &  Loss: 128.04171752929688\n",
            "(Epoch: 150/100) &  Loss: 126.53604888916016\n",
            "(Epoch: 151/100) &  Loss: 125.04923248291016\n",
            "(Epoch: 152/100) &  Loss: 123.58097076416016\n",
            "(Epoch: 153/100) &  Loss: 122.13105773925781\n",
            "(Epoch: 154/100) &  Loss: 120.6993408203125\n",
            "(Epoch: 155/100) &  Loss: 119.28547668457031\n",
            "(Epoch: 156/100) &  Loss: 117.88926696777344\n",
            "(Epoch: 157/100) &  Loss: 116.51045227050781\n",
            "(Epoch: 158/100) &  Loss: 115.14888000488281\n",
            "(Epoch: 159/100) &  Loss: 113.80424499511719\n",
            "(Epoch: 160/100) &  Loss: 112.4765853881836\n",
            "(Epoch: 161/100) &  Loss: 111.16532897949219\n",
            "(Epoch: 162/100) &  Loss: 109.87046813964844\n",
            "(Epoch: 163/100) &  Loss: 108.591796875\n",
            "(Epoch: 164/100) &  Loss: 107.32913970947266\n",
            "(Epoch: 165/100) &  Loss: 106.08203125\n",
            "(Epoch: 166/100) &  Loss: 104.85063171386719\n",
            "(Epoch: 167/100) &  Loss: 103.63459777832031\n",
            "(Epoch: 168/100) &  Loss: 102.43363952636719\n",
            "(Epoch: 169/100) &  Loss: 101.24778747558594\n",
            "(Epoch: 170/100) &  Loss: 100.07670593261719\n",
            "(Epoch: 171/100) &  Loss: 98.920166015625\n",
            "(Epoch: 172/100) &  Loss: 97.7780532836914\n",
            "(Epoch: 173/100) &  Loss: 96.6501693725586\n",
            "(Epoch: 174/100) &  Loss: 95.53636932373047\n",
            "(Epoch: 175/100) &  Loss: 94.43641662597656\n",
            "(Epoch: 176/100) &  Loss: 93.35014343261719\n",
            "(Epoch: 177/100) &  Loss: 92.27751159667969\n",
            "(Epoch: 178/100) &  Loss: 91.2181625366211\n",
            "(Epoch: 179/100) &  Loss: 90.17198181152344\n",
            "(Epoch: 180/100) &  Loss: 89.13878631591797\n",
            "(Epoch: 181/100) &  Loss: 88.11854553222656\n",
            "(Epoch: 182/100) &  Loss: 87.1110610961914\n",
            "(Epoch: 183/100) &  Loss: 86.11597442626953\n",
            "(Epoch: 184/100) &  Loss: 85.13328552246094\n",
            "(Epoch: 185/100) &  Loss: 84.16290283203125\n",
            "(Epoch: 186/100) &  Loss: 83.20450592041016\n",
            "(Epoch: 187/100) &  Loss: 82.25811767578125\n",
            "(Epoch: 188/100) &  Loss: 81.3233871459961\n",
            "(Epoch: 189/100) &  Loss: 80.40032958984375\n",
            "(Epoch: 190/100) &  Loss: 79.48878479003906\n",
            "(Epoch: 191/100) &  Loss: 78.58848571777344\n",
            "(Epoch: 192/100) &  Loss: 77.6994400024414\n",
            "(Epoch: 193/100) &  Loss: 76.82154846191406\n",
            "(Epoch: 194/100) &  Loss: 75.9543685913086\n",
            "(Epoch: 195/100) &  Loss: 75.09806060791016\n",
            "(Epoch: 196/100) &  Loss: 74.25239562988281\n",
            "(Epoch: 197/100) &  Loss: 73.41718292236328\n",
            "(Epoch: 198/100) &  Loss: 72.59226989746094\n",
            "(Epoch: 199/100) &  Loss: 71.7777099609375\n",
            "(Epoch: 200/100) &  Loss: 70.9732437133789\n",
            "(Epoch: 201/100) &  Loss: 70.17872619628906\n",
            "(Epoch: 202/100) &  Loss: 69.39411926269531\n",
            "(Epoch: 203/100) &  Loss: 68.619140625\n",
            "(Epoch: 204/100) &  Loss: 67.85385131835938\n",
            "(Epoch: 205/100) &  Loss: 67.0980224609375\n",
            "(Epoch: 206/100) &  Loss: 66.35163879394531\n",
            "(Epoch: 207/100) &  Loss: 65.6144027709961\n",
            "(Epoch: 208/100) &  Loss: 64.8863296508789\n",
            "(Epoch: 209/100) &  Loss: 64.16727447509766\n",
            "(Epoch: 210/100) &  Loss: 63.4571533203125\n",
            "(Epoch: 211/100) &  Loss: 62.7557487487793\n",
            "(Epoch: 212/100) &  Loss: 62.06312942504883\n",
            "(Epoch: 213/100) &  Loss: 61.378990173339844\n",
            "(Epoch: 214/100) &  Loss: 60.70341873168945\n",
            "(Epoch: 215/100) &  Loss: 60.03608322143555\n",
            "(Epoch: 216/100) &  Loss: 59.377052307128906\n",
            "(Epoch: 217/100) &  Loss: 58.72617721557617\n",
            "(Epoch: 218/100) &  Loss: 58.08339309692383\n",
            "(Epoch: 219/100) &  Loss: 57.4484977722168\n",
            "(Epoch: 220/100) &  Loss: 56.82145309448242\n",
            "(Epoch: 221/100) &  Loss: 56.202171325683594\n",
            "(Epoch: 222/100) &  Loss: 55.59055709838867\n",
            "(Epoch: 223/100) &  Loss: 54.98640823364258\n",
            "(Epoch: 224/100) &  Loss: 54.389801025390625\n",
            "(Epoch: 225/100) &  Loss: 53.800575256347656\n",
            "(Epoch: 226/100) &  Loss: 53.21860885620117\n",
            "(Epoch: 227/100) &  Loss: 52.64379119873047\n",
            "(Epoch: 228/100) &  Loss: 52.07604217529297\n",
            "(Epoch: 229/100) &  Loss: 51.51530075073242\n",
            "(Epoch: 230/100) &  Loss: 50.96150588989258\n",
            "(Epoch: 231/100) &  Loss: 50.414512634277344\n",
            "(Epoch: 232/100) &  Loss: 49.874244689941406\n",
            "(Epoch: 233/100) &  Loss: 49.3406867980957\n",
            "(Epoch: 234/100) &  Loss: 48.813636779785156\n",
            "(Epoch: 235/100) &  Loss: 48.29314422607422\n",
            "(Epoch: 236/100) &  Loss: 47.77899169921875\n",
            "(Epoch: 237/100) &  Loss: 47.271209716796875\n",
            "(Epoch: 238/100) &  Loss: 46.769683837890625\n",
            "(Epoch: 239/100) &  Loss: 46.27422332763672\n",
            "(Epoch: 240/100) &  Loss: 45.78496551513672\n",
            "(Epoch: 241/100) &  Loss: 45.30168914794922\n",
            "(Epoch: 242/100) &  Loss: 44.824337005615234\n",
            "(Epoch: 243/100) &  Loss: 44.35284423828125\n",
            "(Epoch: 244/100) &  Loss: 43.88718795776367\n",
            "(Epoch: 245/100) &  Loss: 43.4272346496582\n",
            "(Epoch: 246/100) &  Loss: 42.97286605834961\n",
            "(Epoch: 247/100) &  Loss: 42.524139404296875\n",
            "(Epoch: 248/100) &  Loss: 42.08086013793945\n",
            "(Epoch: 249/100) &  Loss: 41.64301300048828\n",
            "(Epoch: 250/100) &  Loss: 41.210567474365234\n",
            "(Epoch: 251/100) &  Loss: 40.78338623046875\n",
            "(Epoch: 252/100) &  Loss: 40.36147689819336\n",
            "(Epoch: 253/100) &  Loss: 39.94475173950195\n",
            "(Epoch: 254/100) &  Loss: 39.53313446044922\n",
            "(Epoch: 255/100) &  Loss: 39.12641143798828\n",
            "(Epoch: 256/100) &  Loss: 38.724822998046875\n",
            "(Epoch: 257/100) &  Loss: 38.328125\n",
            "(Epoch: 258/100) &  Loss: 37.93617630004883\n",
            "(Epoch: 259/100) &  Loss: 37.54914093017578\n",
            "(Epoch: 260/100) &  Loss: 37.16678237915039\n",
            "(Epoch: 261/100) &  Loss: 36.78909683227539\n",
            "(Epoch: 262/100) &  Loss: 36.41599655151367\n",
            "(Epoch: 263/100) &  Loss: 36.04745101928711\n",
            "(Epoch: 264/100) &  Loss: 35.68342590332031\n",
            "(Epoch: 265/100) &  Loss: 35.32383346557617\n",
            "(Epoch: 266/100) &  Loss: 34.968589782714844\n",
            "(Epoch: 267/100) &  Loss: 34.617740631103516\n",
            "(Epoch: 268/100) &  Loss: 34.27109909057617\n",
            "(Epoch: 269/100) &  Loss: 33.928741455078125\n",
            "(Epoch: 270/100) &  Loss: 33.590518951416016\n",
            "(Epoch: 271/100) &  Loss: 33.25640106201172\n",
            "(Epoch: 272/100) &  Loss: 32.92633819580078\n",
            "(Epoch: 273/100) &  Loss: 32.600318908691406\n",
            "(Epoch: 274/100) &  Loss: 32.278297424316406\n",
            "(Epoch: 275/100) &  Loss: 31.960107803344727\n",
            "(Epoch: 276/100) &  Loss: 31.645824432373047\n",
            "(Epoch: 277/100) &  Loss: 31.335336685180664\n",
            "(Epoch: 278/100) &  Loss: 31.028636932373047\n",
            "(Epoch: 279/100) &  Loss: 30.725601196289062\n",
            "(Epoch: 280/100) &  Loss: 30.42630958557129\n",
            "(Epoch: 281/100) &  Loss: 30.130634307861328\n",
            "(Epoch: 282/100) &  Loss: 29.838481903076172\n",
            "(Epoch: 283/100) &  Loss: 29.549930572509766\n",
            "(Epoch: 284/100) &  Loss: 29.264801025390625\n",
            "(Epoch: 285/100) &  Loss: 28.983200073242188\n",
            "(Epoch: 286/100) &  Loss: 28.704967498779297\n",
            "(Epoch: 287/100) &  Loss: 28.430065155029297\n",
            "(Epoch: 288/100) &  Loss: 28.158544540405273\n",
            "(Epoch: 289/100) &  Loss: 27.890249252319336\n",
            "(Epoch: 290/100) &  Loss: 27.6252384185791\n",
            "(Epoch: 291/100) &  Loss: 27.36343002319336\n",
            "(Epoch: 292/100) &  Loss: 27.10470962524414\n",
            "(Epoch: 293/100) &  Loss: 26.84914207458496\n",
            "(Epoch: 294/100) &  Loss: 26.59661293029785\n",
            "(Epoch: 295/100) &  Loss: 26.34720802307129\n",
            "(Epoch: 296/100) &  Loss: 26.1007022857666\n",
            "(Epoch: 297/100) &  Loss: 25.857213973999023\n",
            "(Epoch: 298/100) &  Loss: 25.61669921875\n",
            "(Epoch: 299/100) &  Loss: 25.379024505615234\n",
            "(Epoch: 300/100) &  Loss: 25.14419174194336\n",
            "(Epoch: 301/100) &  Loss: 24.91217041015625\n",
            "(Epoch: 302/100) &  Loss: 24.68295669555664\n",
            "(Epoch: 303/100) &  Loss: 24.45648193359375\n",
            "(Epoch: 304/100) &  Loss: 24.232746124267578\n",
            "(Epoch: 305/100) &  Loss: 24.011682510375977\n",
            "(Epoch: 306/100) &  Loss: 23.79323959350586\n",
            "(Epoch: 307/100) &  Loss: 23.57741928100586\n",
            "(Epoch: 308/100) &  Loss: 23.36421775817871\n",
            "(Epoch: 309/100) &  Loss: 23.15353012084961\n",
            "(Epoch: 310/100) &  Loss: 22.945335388183594\n",
            "(Epoch: 311/100) &  Loss: 22.739662170410156\n",
            "(Epoch: 312/100) &  Loss: 22.536396026611328\n",
            "(Epoch: 313/100) &  Loss: 22.3355712890625\n",
            "(Epoch: 314/100) &  Loss: 22.137144088745117\n",
            "(Epoch: 315/100) &  Loss: 21.941116333007812\n",
            "(Epoch: 316/100) &  Loss: 21.747371673583984\n",
            "(Epoch: 317/100) &  Loss: 21.555950164794922\n",
            "(Epoch: 318/100) &  Loss: 21.366809844970703\n",
            "(Epoch: 319/100) &  Loss: 21.17991065979004\n",
            "(Epoch: 320/100) &  Loss: 20.995182037353516\n",
            "(Epoch: 321/100) &  Loss: 20.81268310546875\n",
            "(Epoch: 322/100) &  Loss: 20.63235855102539\n",
            "(Epoch: 323/100) &  Loss: 20.454193115234375\n",
            "(Epoch: 324/100) &  Loss: 20.278079986572266\n",
            "(Epoch: 325/100) &  Loss: 20.104068756103516\n",
            "(Epoch: 326/100) &  Loss: 19.932125091552734\n",
            "(Epoch: 327/100) &  Loss: 19.762216567993164\n",
            "(Epoch: 328/100) &  Loss: 19.594287872314453\n",
            "(Epoch: 329/100) &  Loss: 19.428333282470703\n",
            "(Epoch: 330/100) &  Loss: 19.264333724975586\n",
            "(Epoch: 331/100) &  Loss: 19.102293014526367\n",
            "(Epoch: 332/100) &  Loss: 18.942142486572266\n",
            "(Epoch: 333/100) &  Loss: 18.783885955810547\n",
            "(Epoch: 334/100) &  Loss: 18.627487182617188\n",
            "(Epoch: 335/100) &  Loss: 18.472904205322266\n",
            "(Epoch: 336/100) &  Loss: 18.320209503173828\n",
            "(Epoch: 337/100) &  Loss: 18.169208526611328\n",
            "(Epoch: 338/100) &  Loss: 18.020034790039062\n",
            "(Epoch: 339/100) &  Loss: 17.87261390686035\n",
            "(Epoch: 340/100) &  Loss: 17.726882934570312\n",
            "(Epoch: 341/100) &  Loss: 17.582828521728516\n",
            "(Epoch: 342/100) &  Loss: 17.440555572509766\n",
            "(Epoch: 343/100) &  Loss: 17.299837112426758\n",
            "(Epoch: 344/100) &  Loss: 17.160808563232422\n",
            "(Epoch: 345/100) &  Loss: 17.023420333862305\n",
            "(Epoch: 346/100) &  Loss: 16.887569427490234\n",
            "(Epoch: 347/100) &  Loss: 16.75338363647461\n",
            "(Epoch: 348/100) &  Loss: 16.62069320678711\n",
            "(Epoch: 349/100) &  Loss: 16.48957633972168\n",
            "(Epoch: 350/100) &  Loss: 16.359947204589844\n",
            "(Epoch: 351/100) &  Loss: 16.231815338134766\n",
            "(Epoch: 352/100) &  Loss: 16.1052303314209\n",
            "(Epoch: 353/100) &  Loss: 15.980036735534668\n",
            "(Epoch: 354/100) &  Loss: 15.85637092590332\n",
            "(Epoch: 355/100) &  Loss: 15.734065055847168\n",
            "(Epoch: 356/100) &  Loss: 15.613164901733398\n",
            "(Epoch: 357/100) &  Loss: 15.493698120117188\n",
            "(Epoch: 358/100) &  Loss: 15.375595092773438\n",
            "(Epoch: 359/100) &  Loss: 15.258874893188477\n",
            "(Epoch: 360/100) &  Loss: 15.143463134765625\n",
            "(Epoch: 361/100) &  Loss: 15.029377937316895\n",
            "(Epoch: 362/100) &  Loss: 14.916604995727539\n",
            "(Epoch: 363/100) &  Loss: 14.80510139465332\n",
            "(Epoch: 364/100) &  Loss: 14.694938659667969\n",
            "(Epoch: 365/100) &  Loss: 14.586003303527832\n",
            "(Epoch: 366/100) &  Loss: 14.478317260742188\n",
            "(Epoch: 367/100) &  Loss: 14.371864318847656\n",
            "(Epoch: 368/100) &  Loss: 14.266584396362305\n",
            "(Epoch: 369/100) &  Loss: 14.162557601928711\n",
            "(Epoch: 370/100) &  Loss: 14.05963134765625\n",
            "(Epoch: 371/100) &  Loss: 13.957954406738281\n",
            "(Epoch: 372/100) &  Loss: 13.857419967651367\n",
            "(Epoch: 373/100) &  Loss: 13.758035659790039\n",
            "(Epoch: 374/100) &  Loss: 13.659756660461426\n",
            "(Epoch: 375/100) &  Loss: 13.562578201293945\n",
            "(Epoch: 376/100) &  Loss: 13.466509819030762\n",
            "(Epoch: 377/100) &  Loss: 13.371559143066406\n",
            "(Epoch: 378/100) &  Loss: 13.277630805969238\n",
            "(Epoch: 379/100) &  Loss: 13.184773445129395\n",
            "(Epoch: 380/100) &  Loss: 13.092997550964355\n",
            "(Epoch: 381/100) &  Loss: 13.002197265625\n",
            "(Epoch: 382/100) &  Loss: 12.912469863891602\n",
            "(Epoch: 383/100) &  Loss: 12.82374095916748\n",
            "(Epoch: 384/100) &  Loss: 12.735968589782715\n",
            "(Epoch: 385/100) &  Loss: 12.64921760559082\n",
            "(Epoch: 386/100) &  Loss: 12.563408851623535\n",
            "(Epoch: 387/100) &  Loss: 12.478540420532227\n",
            "(Epoch: 388/100) &  Loss: 12.394667625427246\n",
            "(Epoch: 389/100) &  Loss: 12.311721801757812\n",
            "(Epoch: 390/100) &  Loss: 12.229654312133789\n",
            "(Epoch: 391/100) &  Loss: 12.14856243133545\n",
            "(Epoch: 392/100) &  Loss: 12.068300247192383\n",
            "(Epoch: 393/100) &  Loss: 11.988970756530762\n",
            "(Epoch: 394/100) &  Loss: 11.910505294799805\n",
            "(Epoch: 395/100) &  Loss: 11.8329439163208\n",
            "(Epoch: 396/100) &  Loss: 11.756179809570312\n",
            "(Epoch: 397/100) &  Loss: 11.680307388305664\n",
            "(Epoch: 398/100) &  Loss: 11.605228424072266\n",
            "(Epoch: 399/100) &  Loss: 11.531004905700684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKgMF51e1PFE",
        "outputId": "099aec62-80af-4137-d076-8d4cf3daf6bd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.9893,  69.4484],\n",
              "        [ 81.5940,  97.8730],\n",
              "        [118.7667, 140.6984],\n",
              "        [ 24.3170,  33.4585],\n",
              "        [ 99.2575, 116.0088]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=MSE(preds,target)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAJzLzDU1pNR",
        "outputId": "d9499e70-fd32-44b8-9c69-77d7238faefe"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11.4576, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "sqrt(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsYMpdti1qJ-",
        "outputId": "2ab933df-2f99-4725-ebd2-3d0af51d5643"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.384905090804598"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfJdwyOY1z-f",
        "outputId": "0b7cbfe1-59d3-40bc-bd16-6e9f9139d488"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.9893,  69.4484],\n",
              "        [ 81.5940,  97.8730],\n",
              "        [118.7667, 140.6984],\n",
              "        [ 24.3170,  33.4585],\n",
              "        [ 99.2575, 116.0088]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3u_QUN612sN",
        "outputId": "ee0e62de-af54-4543-b060-8c036a9a4b70"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Neural Network using PyTorch\n",
        "\n",
        "### ðŸ” GPU Availability Check\n",
        "\n",
        "To check if GPU is available for training models in Google Colab:\n",
        "\n",
        "```python\n",
        "# To check GPU availability\n",
        "!nvidia-smi\n",
        "```\n",
        "\n",
        "### ðŸ–¥ï¸ Sample Output:\n",
        "\n",
        "```\n",
        "Wed May 24 08:25:17 2023\n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      | MIG M.               |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   42C    P8     9W /  70W |     3MiB / 15360MiB  |      0%      Default |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "\n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Œ Notes:\n",
        "\n",
        "* `Tesla T4`: This is the GPU available in Google Colab.\n",
        "* `Memory-Usage`: Only 3 MiB used out of 15,360 MiB (i.e., \\~15 GB).\n",
        "* `GPU-Util`: 0% â†’ GPU is currently **idle**, ready for use.\n",
        "* **No running processes found** â†’ No model is currently using the GPU.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Use Case:\n",
        "\n",
        "Before training deep learning models in PyTorch, it's a good practice to check if GPU is available. It significantly speeds up training time compared to CPU.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "7Jvr78Fh2JWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4fbd4vzc2pxy"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huPC0KIO2r0f",
        "outputId": "64bdd27f-c3f4-4677-eae8-df5a7ebc82f1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.4M/26.4M [00:01<00:00, 20.7MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.5k/29.5k [00:00<00:00, 335kB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.42M/4.42M [00:00<00:00, 6.06MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.15k/5.15k [00:00<00:00, 17.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "sLC93pGc2udT"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "WdbnE_0p16DC",
        "outputId": "2a9ebce2-e456-413a-9538-75a3ec933b8d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: Union[str, Path], train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (str or ``pathlib.Path``): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.\n",
              "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 204);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape}, {y.dtype}\")\n",
        "    # print(X)\n",
        "    # print(y)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI3tQWHo26GZ",
        "outputId": "894bd72d-0175-456e-9171-8efc5aa3a9cf"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]), torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBAOqQCf3RuR",
        "outputId": "eeebf93a-7937-4c2a-e2bb-92a6a5638a5f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6pfmcXk3V52",
        "outputId": "ce8e8c87-743c-43c0-9bcc-6e2f359ec534"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "qrq67Le23-Xp"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ],
      "metadata": {
        "id": "6_-25v1s3p73"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "85vaE4f74BAo"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE14QdjL4RXx",
        "outputId": "7e3ca342-ccc6-4a2f-eb41-67fc99e9a975"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299036  [    0/60000]\n",
            "loss: 2.292254  [ 6400/60000]\n",
            "loss: 2.264594  [12800/60000]\n",
            "loss: 2.264613  [19200/60000]\n",
            "loss: 2.256015  [25600/60000]\n",
            "loss: 2.217301  [32000/60000]\n",
            "loss: 2.226303  [38400/60000]\n",
            "loss: 2.189348  [44800/60000]\n",
            "loss: 2.196368  [51200/60000]\n",
            "loss: 2.159278  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 48.7%, Avg loss: 2.145223 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.157396  [    0/60000]\n",
            "loss: 2.155075  [ 6400/60000]\n",
            "loss: 2.080441  [12800/60000]\n",
            "loss: 2.107667  [19200/60000]\n",
            "loss: 2.055507  [25600/60000]\n",
            "loss: 1.985938  [32000/60000]\n",
            "loss: 2.027066  [38400/60000]\n",
            "loss: 1.935456  [44800/60000]\n",
            "loss: 1.957864  [51200/60000]\n",
            "loss: 1.883225  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.1%, Avg loss: 1.866807 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.899794  [    0/60000]\n",
            "loss: 1.880609  [ 6400/60000]\n",
            "loss: 1.736744  [12800/60000]\n",
            "loss: 1.800181  [19200/60000]\n",
            "loss: 1.681061  [25600/60000]\n",
            "loss: 1.626066  [32000/60000]\n",
            "loss: 1.668785  [38400/60000]\n",
            "loss: 1.554243  [44800/60000]\n",
            "loss: 1.594967  [51200/60000]\n",
            "loss: 1.494197  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.2%, Avg loss: 1.495704 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.556855  [    0/60000]\n",
            "loss: 1.536833  [ 6400/60000]\n",
            "loss: 1.366350  [12800/60000]\n",
            "loss: 1.459100  [19200/60000]\n",
            "loss: 1.332131  [25600/60000]\n",
            "loss: 1.323154  [32000/60000]\n",
            "loss: 1.349057  [38400/60000]\n",
            "loss: 1.264252  [44800/60000]\n",
            "loss: 1.308111  [51200/60000]\n",
            "loss: 1.211152  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.1%, Avg loss: 1.229514 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.298056  [    0/60000]\n",
            "loss: 1.297531  [ 6400/60000]\n",
            "loss: 1.115693  [12800/60000]\n",
            "loss: 1.237003  [19200/60000]\n",
            "loss: 1.111508  [25600/60000]\n",
            "loss: 1.125694  [32000/60000]\n",
            "loss: 1.155168  [38400/60000]\n",
            "loss: 1.086153  [44800/60000]\n",
            "loss: 1.131601  [51200/60000]\n",
            "loss: 1.048837  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.7%, Avg loss: 1.066455 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umQBquW_4wKB",
        "outputId": "031bb32c-5bd0-4f2f-c384-baa502223860"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "print(\"<All keys matched successfully>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPE2LG_n4yQ6",
        "outputId": "8940b378-061e-4007-d17d-fec452a14c6f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<All keys matched successfully>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\"\n",
        "]\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]"
      ],
      "metadata": {
        "id": "721ir3PV41PY"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjM-OtxH4UUJ",
        "outputId": "3a068944-8818-4f29-99eb-6a1550fa81f0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    }
  ]
}